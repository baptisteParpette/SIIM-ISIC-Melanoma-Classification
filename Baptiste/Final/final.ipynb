{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2438256369.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 66\u001b[1;36m\u001b[0m\n\u001b[1;33m    img_dir='C:\\\\Users\\\\benoi\\\\Downloads\\\\isic-2020-resized\\\\train-resized\\\\train-resized'     # Ajustez le chemin\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Modification du code de l'utilisateur pour répondre aux objectifs identifiés\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Créer un écrivain SummaryWriter\n",
    "writer = SummaryWriter('runs/melanoma_experiment_22')  # Ajustez le chemin\n",
    "\n",
    "# Vérifier si CUDA est disponible, sinon utiliser le CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Architecture simplifiée du CNN\n",
    "class MelanomaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MelanomaCNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 112 * 112, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16 * 112 * 112)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "\n",
    "# Ensemble de données personnalisé\n",
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, limit=None):\n",
    "        self.labels_df = pd.read_csv(csv_file).head(limit)  # Limite à 100 images\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.labels_df.iloc[idx, 0] + \".jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        label = torch.tensor(self.labels_df.iloc[idx, 1], dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformations pour les images\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Charger l'ensemble de données\n",
    "full_dataset = MelanomaDataset(csv_file='C:\\\\Users\\\\benoi\\\\Downloads\\\\isic-2020-resized\\\\train-labels.csv',  # Ajustez le chemin\n",
    "                                img_dir='C:\\\\Users\\\\benoi\\\\Downloads\\\\isic-2020-resized\\\\train-resized\\\\train-resized',    # Ajustez le chemin\n",
    "                               transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer l'ensemble de données en ensembles d'entraînement et de validation\n",
    "train_size = int(0.8 * len(full_dataset))  # 80% pour l'entraînement\n",
    "val_size = len(full_dataset) - train_size  # 20% pour la validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Fonction adaptée pour compter les fréquences des classes directement dans un dataset\n",
    "def count_class_frequencies(dataset):\n",
    "    class_counts = {0: 0, 1: 0}\n",
    "    for _, label in dataset:\n",
    "        class_counts[int(label.item())] += 1\n",
    "    return class_counts\n",
    "\n",
    "def create_sampler_for_subset(dataset, subset_indices):\n",
    "    class_counts = count_class_frequencies(dataset)\n",
    "    weights = [1.0 / class_counts[int(dataset[idx][1].item())] for idx in subset_indices]\n",
    "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "# Indices pour chaque subset\n",
    "train_indices = train_dataset.indices\n",
    "val_indices = val_dataset.indices\n",
    "\n",
    "# Créer un sampler pour chaque subset\n",
    "train_sampler = create_sampler_for_subset(full_dataset, train_indices)\n",
    "val_sampler = create_sampler_for_subset(full_dataset, val_indices)\n",
    "\n",
    "# Utiliser le sampler correct pour chaque DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler, pin_memory=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, sampler=val_sampler, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bapti\\Desktop\\SIIM-ISIC-Melanoma-Classification\\Baptiste\\NewTest\\final.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bapti/Desktop/SIIM-ISIC-Melanoma-Classification/Baptiste/NewTest/final.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bapti/Desktop/SIIM-ISIC-Melanoma-Classification/Baptiste/NewTest/final.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bapti/Desktop/SIIM-ISIC-Melanoma-Classification/Baptiste/NewTest/final.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bapti/Desktop/SIIM-ISIC-Melanoma-Classification/Baptiste/NewTest/final.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m train_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m calculate_accuracy(target, outputs)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bapti/Desktop/SIIM-ISIC-Melanoma-Classification/Baptiste/NewTest/final.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m predictions \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mge(\u001b[39m.5\u001b[39m)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger le modèle pré-entraîné ResNet50 et dégeler tous les paramètres\n",
    "model = models.resnet50(weights=\"ResNet50_Weights.IMAGENET1K_V2\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True  # Entraîner tout le modèle\n",
    "\n",
    "# Remplacer la dernière couche fc pour la classification binaire\n",
    "model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 1), nn.Sigmoid())\n",
    "model = model.to(device)\n",
    "\n",
    "# Fonction de perte et optimiseur\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimiser tous les paramètres\n",
    "\n",
    "# Fonction pour calculer la précision\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    predicted = y_pred.ge(.5).view(-1)\n",
    "    return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "# Supposons que vous avez 2 classes (0 et 1)\n",
    "num_classes = 2\n",
    "\n",
    "# Entraîner le modèle\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    # Initialisation des compteurs par classe pour l'entraînement\n",
    "    correct_pred_train = {classname: 0 for classname in range(num_classes)}\n",
    "    total_pred_train = {classname: 0 for classname in range(num_classes)}\n",
    "    \n",
    "    model.train()\n",
    "    train_loss, train_accuracy, train_precision, train_recall = 0, 0, 0, 0\n",
    "\n",
    "    # Boucle d'entraînement\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Training Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).squeeze()\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += calculate_accuracy(target, outputs).item()\n",
    "        predictions = outputs.ge(.5).float()\n",
    "        train_precision += precision_score(target.cpu(), predictions.cpu(), zero_division=0)\n",
    "        train_recall += recall_score(target.cpu(), predictions.cpu(), zero_division=0)\n",
    "\n",
    "        # Mettre à jour les compteurs par classe\n",
    "        predictions = outputs.ge(.5).float()\n",
    "        for label, prediction in zip(target, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred_train[int(label.item())] += 1\n",
    "            total_pred_train[int(label.item())] += 1\n",
    "\n",
    "    for classname in range(num_classes):\n",
    "        precision = 100 * float(correct_pred_train[classname]) / total_pred_train[classname]\n",
    "        recall = 100 * float(correct_pred_train[classname]) / total_pred_train[classname]\n",
    "        writer.add_scalar(f'Train/Precision_class_{classname}', precision, epoch)\n",
    "        writer.add_scalar(f'Train/Recall_class_{classname}', recall, epoch)\n",
    "\n",
    "    # Réinitialisation des compteurs pour la validation\n",
    "    correct_pred_val = {classname: 0 for classname in range(num_classes)}\n",
    "    total_pred_val = {classname: 0 for classname in range(num_classes)}\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy /= len(train_loader)\n",
    "    train_precision /= len(train_loader)\n",
    "    train_recall /= len(train_loader)\n",
    "    \n",
    "    # Enregistrement des métriques d'entraînement dans TensorBoard\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
    "    writer.add_scalar('Precision/Train', train_precision, epoch)\n",
    "    writer.add_scalar('Recall/Train', train_recall, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy, val_precision, val_recall = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data).squeeze()\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += calculate_accuracy(target, outputs).item()\n",
    "\n",
    "            predictions = outputs.ge(.5).float()\n",
    "            val_precision += precision_score(target.cpu(), predictions.cpu(), zero_division=0)\n",
    "            val_recall += recall_score(target.cpu(), predictions.cpu(), zero_division=0)\n",
    "\n",
    "            # Mettre à jour les compteurs par classe\n",
    "            predictions = outputs.ge(.5).float()\n",
    "            for label, prediction in zip(target, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred_val[int(label.item())] += 1\n",
    "                total_pred_val[int(label.item())] += 1\n",
    "        \n",
    "        # Calculer la précision et le rappel par classe pour la validation\n",
    "    for classname in range(num_classes):\n",
    "        precision = 100 * float(correct_pred_val[classname]) / total_pred_val[classname]\n",
    "        recall = 100 * float(correct_pred_val[classname]) / total_pred_val[classname]\n",
    "        writer.add_scalar(f'Validation/Precision_class_{classname}', precision, epoch)\n",
    "        writer.add_scalar(f'Validation/Recall_class_{classname}', recall, epoch)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy /= len(val_loader)\n",
    "    val_precision /= len(val_loader)\n",
    "    val_recall /= len(val_loader)\n",
    "\n",
    "    # Enregistrement des métriques de validation dans TensorBoard\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "    writer.add_scalar('Precision/Validation', val_precision, epoch)\n",
    "    writer.add_scalar('Recall/Validation', val_recall, epoch)\n",
    "\n",
    "\n",
    "    # Affichage des statistiques pour chaque époque\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "torch.save(model.state_dict(), 'melanoma_model2.pth')\n",
    "\n",
    "# Fermer le SummaryWriter\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
