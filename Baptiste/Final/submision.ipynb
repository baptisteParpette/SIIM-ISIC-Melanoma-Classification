{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Vérifier si CUDA est disponible, sinon utiliser le CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Architecture simplifiée du CNN\n",
    "class MelanomaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MelanomaCNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 112 * 112, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16 * 112 * 112)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class MelanomaTestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, limit=None):\n",
    "        self.img_names = os.listdir(img_dir)[:limit]  # Ajoutez la limitation ici\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.img_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benoi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benoi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'melanoma_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benoi\\OneDrive - INSA Lyon\\4A\\TIP\\SIIM-ISIC-Melanoma-Classification\\Baptiste\\Final\\submision.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(\u001b[39m2048\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     nn\u001b[39m.\u001b[39mSigmoid()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Charger les poids du modèle fine-tuné\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmelanoma_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))  \u001b[39m# Mettez à jour le chemin\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benoi/OneDrive%20-%20INSA%20Lyon/4A/TIP/SIIM-ISIC-Melanoma-Classification/Baptiste/Final/submision.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'melanoma_model.pth'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Charger ResNet50 (sans les poids pré-entraînés pour le moment)\n",
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# Remplacer la dernière couche fc pour notre classification binaire\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Charger les poids du modèle fine-tuné\n",
    "model.load_state_dict(torch.load('melanoma_model2.pth'))  # Mettez à jour le chemin\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "test_dataset = MelanomaTestDataset(img_dir='C:\\\\Users\\\\benoi\\\\Downloads\\\\isic-2020-resized\\\\test-resized\\\\test-resized', transform=transform)  # Mettez à jour le chemin\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer des prédictions\n",
    "predictions = []\n",
    "image_names = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, names in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data).squeeze()\n",
    "        # Convertir les sorties tensor en liste de valeurs flottantes\n",
    "        predictions.extend(outputs.tolist())\n",
    "        # Retirer l'extension des noms d'image\n",
    "        image_names.extend([n.split('.')[0] for n in names])\n",
    "\n",
    "# Générer un fichier CSV pour la soumission\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_name': image_names,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_resnet50.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
